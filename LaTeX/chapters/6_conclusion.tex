This thesis embarked on a comprehensive investigation into the efficacy of modern machine learning techniques for the calibration of the one-factor \ac{hw} interest rate model. The central objective was to move beyond traditional iterative optimization and determine whether a deep \ac{nn}, trained end-to-end, could provide a more accurate, stable, and computationally efficient alternative to the well-established \ac{lm} algorithm. The research was guided by three core questions concerning the comparative accuracy in pricing unseen swaptions, the quantitative difference in computational speed, and the temporal stability of the derived model parameters.

The empirical results address these primary research questions, suggesting that within the context of this study, the \ac{nn}-based approach yielded different performance characteristics compared to the \ac{lm} method. In terms of pricing accuracy, the \ac{nn} achieved a mean out-of-sample \ac{rmse} that was lower and exhibited less variance than the tested \ac{lm} strategies, which may indicate an enhanced ability to generalize to unseen market data.

Regarding computational efficiency, a substantial difference was observed; calibration times for the \ac{nn} were measured in milliseconds, resulting in a computational speedup of several orders of magnitude, approximately 17,000 times faster, compared to the iterative \ac{lm} implementation. This finding is consistent with the results observed in related literature, with \textcite{alaya2021deep} reporting a speedup of 7,600 times when applying a \ac{nn} to the calibration of the G2++ model.

The analysis of parameter stability indicates that the \ac{nn} produced stable parameter trajectories that responded coherently to simulated market shocks. In contrast, the \ac{lm} strategies appeared more susceptible to numerical instability and parameter drift, with their performance showing a high sensitivity to the initial guess strategy.

The findings of this thesis may have implications for financial modeling. The observed performance difference suggests a potential advantage in the end-to-end training approach, which, unlike the benchmark study by \textcite{hernandez2016model}, allows the \ac{nn} to directly minimize the pricing error. This may permit the \ac{nn} to identify parameter mappings that are not constrained by the local minima of traditional optimizers. Furthermore, the \ac{shap} analysis pointed to the importance of the economically-motivated feature engineering, as the model learned to prioritize yield curve curvature and systemic risk indicators in a manner consistent with financial theory. From a practical standpoint, the results indicate that the sub-second calibration time of the \ac{nn} could make applications such as real-time risk management and intraday recalibration operationally feasible. The observed accuracy and parameter stability could provide a more reliable foundation for pricing other derivatives.

Nonetheless, this research is subject to several limitations. The analysis was restricted to a one-factor \ac{hw} model calibrated exclusively to European \ac{atm} swaptions, omitting multi-factor models, other derivative instruments, and the volatility smile or skew. The dataset covers only a short, three-month period in a single currency market, limiting generalizability across different economic cycles and the assessment of long-term performance stability. Feature selection was not systematically performed, potentially constraining model performance. Furthermore, the \ac{nn} approach entails a substantial upfront investment in training and hyperparameter tuning, and despite \ac{shap}-based interpretability, its "black box" nature presents challenges for model validation, governance, and regulatory approval.

The empirical evidence from this thesis leads to several considerations. For users of the traditional \ac{lm} method, the results suggest that the algorithm's performance is sensitive to its initial guess, as evidenced by the performance degradation of the 'Pure Rolling' strategy. It seems that more robust initialization strategies, such as the 'Adaptive Anchor' approach, may be beneficial for mitigating parameter drift. For developers of machine learning models in finance, the results suggest a potential value in integrating domain knowledge through feature engineering, as the \ac{nn}'s use of curated features was a notable component of its performance. The direct optimization of the pricing error also appeared to be an effective training paradigm in this study, suggesting that such end-to-end learning frameworks could be a valuable approach for developing surrogate calibration models. 

Future research should extend the framework to multi-factor interest rate models like the G2++ model to capture more complex yield curve dynamics and incorporate \ac{otm} and \ac{itm} swaptions to account for the volatility smile. Evaluating hedge performance through the accuracy, stability, and P\&L impact of derived hedge parameters would provide a more comprehensive assessment. Validation over longer time horizons and across diverse market conditions would provide deeper insights into the \ac{nn}'s behavior under varying market regimes. Systematic feature selection using techniques such as backward elimitation, could further improve model robustness. Exploring advanced \ac{nn} architectures, such as recurrent networks or transformers, may enhance the capture of temporal dependencies in market data. A significant enhancement to the residual learning framework could be the adoption of a dynamic initial guess, leveraging the parameters from the previous day, to focus the learning task on modeling daily parameter dynamics rather than absolute levels, potentially improving both stability and convergence speed. Finally, re-implementing the \ac{hw} swaption pricing logic in a fully GPU-accelerated and differentiable framework, eliminating numerical gradient approximations, could dramatically reduce training times, enable more extensive hyperparameter exploration and thereby potentially enhance model performance. Should a fully differentiable pricing engine not be feasible, an intermediate step could involve altering the training target from volatility to price. This would entail converting the market swaption volatility surface to a corresponding price surface in a one-time preprocessing step. The \ac{nn} would then be trained to minimize the error between the model-generated prices and these market prices. Such an approach would circumvent the computationally expensive, iterative root-finding algorithm required to invert prices back to implied volatilities within the training loop. This would significantly accelerate both the hyperparameter optimization and final training phases, while the model's core task, learning the parameters of the \ac{hw} model, would remain unchanged.