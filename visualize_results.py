"""
Script for Visualizing Hull-White Calibration Comparison Results

Objective:
This script reads the output CSV files generated by `run_comparison.py` and
produces a comprehensive set of tables and plots to visualize the results
of the model comparison.

The script generates two categories of visualizations:
1.  High-level performance summaries based on `daily_summary_results.csv`.
2.  Granular, instrument-level analysis based on `per_swaption_holdout_results.csv`.

All generated tables (as .txt and .csv) and plots (as .png) are saved in the
same directory where the source CSV files are located.
"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib import cm

# --- CONFIGURATION ---
BASE_DIR = os.getcwd()
RESULTS_DIR = os.path.join(BASE_DIR, 'results')
COMPARISON_DIR = os.path.join(RESULTS_DIR, 'comparison')

# Input files
SUMMARY_CSV = os.path.join(COMPARISON_DIR, 'daily_summary_results.csv')
SUMMARY_CSV_BLACK = os.path.join(COMPARISON_DIR, 'daily_summary_results_black.csv')
SWAPTION_CSV = os.path.join(COMPARISON_DIR, 'per_swaption_holdout_results.csv')

# --- PLOT STYLING ---
# Use the 'coolwarm' colormap for consistent branding: blue for NN, red for LM
NN_COLOR = cm.get_cmap('coolwarm', 10)(1)  # A nice blue
LM_COLOR = cm.get_cmap('coolwarm', 10)(9)  # A nice red
MODEL_PALETTE = {"Neural Network": NN_COLOR, "Levenberg-Marquardt": LM_COLOR}
sns.set_theme(style="whitegrid")

# --- HELPER FUNCTIONS ---
def parse_tenor_to_years(tenor_str: str) -> float:
    """
    Parses a tenor string (e.g., '10YR', '6MO') into a float representing years.

    Args:
        tenor_str (str): The tenor string to be parsed.

    Returns:
        float: The parsed tenor in years. If the parsing fails, returns np.nan.

    Raises:
        ValueError: If the parsing fails due to an invalid tenor string.
    """
    try:
        tenor_str = str(tenor_str).strip().upper()
        if 'YR' in tenor_str: return float(tenor_str.replace('YR', ''))
        if 'MO' in tenor_str: return float(tenor_str.replace('MO', '')) / 12.0
    except (ValueError, AttributeError):
        return np.nan
    raise ValueError(f"Could not parse tenor string to years: {tenor_str}")

# --- PART 1: DAILY SUMMARY ANALYSIS ---
def generate_summary_tables(df: pd.DataFrame, save_dir: str):
    """
    Generates three summary tables from the daily_summary_results.csv file and saves them to
    the specified directory.

    The three tables are:
    1. Aggregate Out-of-Sample Performance Metrics (RMSE in bps)
    2. Computational Efficiency
    3. Parameter Stability Analysis

    Args:
        df (pd.DataFrame): The DataFrame containing the daily comparison results.
        save_dir (str): The directory where the summary tables will be saved.

    Returns:
        None
    """
    print("="*80)
    print(" GENERATING SUMMARY TABLES FROM daily_summary_results.csv ".center(80, "="))
    print("="*80)
    os.makedirs(save_dir, exist_ok=True)

    # --- Table 1: Aggregate Out-of-Sample Performance Metrics ---
    rmse_stats = df[['RMSE_NN_OutOfSample', 'RMSE_LM_OutOfSample']].agg(['mean', 'std', 'median', 'min', 'max']).T
    rmse_stats.columns = ['Mean', 'Std Dev', 'Median', 'Min', 'Max']
    rmse_stats.index = ['Neural Network', 'Levenberg-Marquardt']
    print("\n--- Table 1: Aggregate Out-of-Sample Performance Metrics (RMSE in bps) ---")
    print(rmse_stats.to_string(float_format="%.4f"))
    
    # Save Table 1
    rmse_stats.to_csv(os.path.join(save_dir, 'table1_performance_metrics.csv'))
    with open(os.path.join(save_dir, 'table1_performance_metrics.txt'), 'w') as f:
        f.write("Table 1: Aggregate Out-of-Sample Performance Metrics (RMSE in bps)\n")
        f.write(rmse_stats.to_string(float_format="%.4f"))
    print(f"\nSaved Table 1 to '{save_dir}'")

    # --- Table 2: Computational Efficiency ---
    time_stats = df[['Time_NN_sec', 'Time_LM_sec']].agg(['mean', 'std']).T
    time_stats.columns = ['Mean Time (s)', 'Std Dev Time (s)']
    time_stats.index = ['Neural Network', 'Levenberg-Marquardt']
    print("\n--- Table 2: Computational Efficiency ---")
    print(time_stats.to_string(float_format="%.6f"))
    
    speedup = time_stats.loc['Levenberg-Marquardt', 'Mean Time (s)'] / time_stats.loc['Neural Network', 'Mean Time (s)']
    print(f"\nAverage Speed-up Factor (NN vs LM): {speedup:.2f}x")
    
    # Save Table 2
    time_stats.to_csv(os.path.join(save_dir, 'table2_computational_efficiency.csv'))
    with open(os.path.join(save_dir, 'table2_computational_efficiency.txt'), 'w') as f:
        f.write("Table 2: Computational Efficiency\n")
        f.write(time_stats.to_string(float_format="%.6f"))
        f.write(f"\n\nAverage Speed-up Factor (NN vs LM): {speedup:.2f}x")
    print(f"Saved Table 2 to '{save_dir}'")

    # --- Table 3: Parameter Stability Analysis ---
    param_cols = [col for col in df.columns if 'NN_param_' in col or 'LM_param_' in col]
    if not param_cols: # Legacy format support
        param_cols = [col for col in df.columns if col.startswith(('NN_a', 'LM_a', 'NN_sigma', 'LM_sigma'))]
    
    if param_cols:
        param_stats = df[param_cols].agg(['mean', 'std']).T
        param_stats.columns = ['Mean', 'Std Dev']
        print("\n--- Table 3: Parameter Stability Analysis ---")
        print(param_stats.to_string(float_format="%.6f"))
        
        # Save Table 3
        param_stats.to_csv(os.path.join(save_dir, 'table3_parameter_stability.csv'))
        with open(os.path.join(save_dir, 'table3_parameter_stability.txt'), 'w') as f:
            f.write("Table 3: Parameter Stability Analysis\n")
            f.write(param_stats.to_string(float_format="%.6f"))
        print(f"Saved Table 3 to '{save_dir}'")
    else:
        print("\n--- Table 3: No parameter columns found for stability analysis ---")
    
    print("\n" + "="*80 + "\n")

def plot_daily_rmse(df: pd.DataFrame, save_path: str):
    """
    Plot 1: Daily Out-of-Sample RMSE Over Time

    Plots the daily out-of-sample RMSE for both the Neural Network and Levenberg-Marquardt models.

    Parameters
    ----------
    df : pd.DataFrame
        The DataFrame containing the daily comparison results.
    save_path : str
        The path where the plot will be saved.

    Returns
    -------
    None
    """
    fig, ax = plt.subplots(figsize=(14, 7))
    ax.plot(df['Date'], df['RMSE_NN_OutOfSample'], label='Neural Network', color=NN_COLOR, marker='o', linestyle='-', markersize=4)
    ax.plot(df['Date'], df['RMSE_LM_OutOfSample'], label='Levenberg-Marquardt', color=LM_COLOR, marker='x', linestyle='--', markersize=5)
    ax.set_title('Daily Out-of-Sample RMSE Over Time', fontsize=16)
    ax.set_xlabel('Date', fontsize=12)
    ax.set_ylabel('RMSE (bps)', fontsize=12)
    ax.legend()
    ax.grid(True, which='both', linestyle='--')
    fig.autofmt_xdate()
    plt.tight_layout()
    plt.savefig(save_path)
    plt.close(fig)
    print(f"Saved Plot 1: {save_path}")

def plot_daily_rmse_black(df: pd.DataFrame, save_path: str):
    """
    Plot: Daily Out-of-Sample RMSE Over Time (Black Volatility)

    Plots the daily out-of-sample RMSE for both models, showing both the
    vega-weighted and simple average errors in log-normal (Black) volatility terms.

    Parameters
    ----------
    df : pd.DataFrame
        The DataFrame containing the daily comparison results for Black volatility.
    save_path : str
        The path where the plot will be saved.

    Returns
    -------
    None
    """
    fig, ax = plt.subplots(figsize=(14, 8))

    ax.plot(df['Date'], df['BlackVol_NN_Vega_Weighted'], label='Neural Network (Vega Weighted)',
            color=NN_COLOR, marker='o', linestyle='-', markersize=4)
    ax.plot(df['Date'], df['BlackVol_LM_Vega_Weighted'], label='Levenberg-Marquardt (Vega Weighted)',
            color=LM_COLOR, marker='o', linestyle='-', markersize=4)

    ax.plot(df['Date'], df['BlackVol_NN_Simple_Avg'], label='Neural Network (Simple Average)',
            color=NN_COLOR, linestyle=':', marker=None)
    ax.plot(df['Date'], df['BlackVol_LM_Simple_Avg'], label='Levenberg-Marquardt (Simple Average)',
            color=LM_COLOR, linestyle=':', marker=None)

    ax.set_title('Daily Out-of-Sample RMSE Over Time (Black Volatility)', fontsize=16)
    ax.set_xlabel('Date', fontsize=12)
    ax.set_ylabel('RMSE (Black Volatility) in %', fontsize=12)
    ax.legend()
    ax.grid(True, which='both', linestyle='--')
    fig.autofmt_xdate()
    plt.tight_layout()
    plt.savefig(save_path)
    plt.close(fig)
    print(f"Saved Black Volatility RMSE Plot: {save_path}")

def plot_rmse_distribution(df: pd.DataFrame, save_path: str):
    """
    Plot 2: Distribution of Daily Out-of-Sample RMSE

    Plots a violin plot showing the distribution of daily out-of-sample RMSE for both the Neural Network and Levenberg-Marquardt models.

    Parameters
    ----------
    df : pd.DataFrame
        The DataFrame containing the daily comparison results.
    save_path : str
        The path where the plot will be saved.

    Returns
    -------
    None
    """
    df_melted = df.melt(
        id_vars=['Date'],
        value_vars=['RMSE_NN_OutOfSample', 'RMSE_LM_OutOfSample'],
        var_name='Model',
        value_name='Daily RMSE (bps)'
    )
    df_melted['Model'] = df_melted['Model'].map({
        'RMSE_NN_OutOfSample': 'Neural Network',
        'RMSE_LM_OutOfSample': 'Levenberg-Marquardt'
    })

    fig, ax = plt.subplots(figsize=(10, 7))
    sns.violinplot(data=df_melted, x='Model', y='Daily RMSE (bps)', palette=MODEL_PALETTE, ax=ax, cut=0)
    ax.set_title('Distribution of Daily Out-of-Sample RMSE', fontsize=16)
    ax.set_xlabel('Model', fontsize=12)
    ax.set_ylabel('Daily RMSE (bps)', fontsize=12)
    plt.tight_layout()
    plt.savefig(save_path)
    plt.close(fig)
    print(f"Saved Plot 2: {save_path}")

def plot_parameter_evolution(df: pd.DataFrame, save_path: str):
    """
    Plot 3: Comparison of Model Parameter Evolution

    Plots a comparison of the evolution of the model parameters over time on two subplots.
    The top plot shows the 'alpha' parameter, and the bottom plot shows all 'sigma' parameters.

    Parameters
    ----------
    df : pd.DataFrame
        The DataFrame containing the daily comparison results.
    save_path : str
        The path where the plot will be saved.

    Returns
    -------
    None
    """
    # Find alpha parameter columns (handles legacy and new formats)
    nn_alpha_col = next((c for c in df.columns if c in ['NN_param_a', 'NN_a_1']), None)
    lm_alpha_col = next((c for c in df.columns if c in ['LM_param_a', 'LM_a_1']), None)

    # Find all sigma parameter columns
    nn_sigma_cols = sorted([c for c in df.columns if 'NN_sigma' in c])
    lm_sigma_cols = sorted([c for c in df.columns if 'LM_sigma' in c])

    # --- Validation ---
    if not nn_alpha_col or not lm_alpha_col:
        print("Could not generate Plot 3: Alpha parameter columns not found.")
        return
    if not nn_sigma_cols or not lm_sigma_cols:
        print("Could not generate Plot 3: Sigma parameter columns not found.")
        return

    # --- Plotting ---
    fig, axes = plt.subplots(2, 1, figsize=(15, 10), sharex=True)
    fig.suptitle('Comparison of Model Parameter Evolution', fontsize=18, y=0.95)

    # --- Subplot 1: Alpha Parameter ---
    axes[0].plot(df['Date'], df[nn_alpha_col], color=NN_COLOR, linestyle='-', label=nn_alpha_col)
    axes[0].plot(df['Date'], df[lm_alpha_col], color=LM_COLOR, linestyle='--', label=lm_alpha_col)
    axes[0].set_title('Evolution of Mean-Reversion Parameter (Alpha)', fontsize=14)
    axes[0].set_ylabel('Parameter Value', fontsize=12)
    axes[0].legend()
    axes[0].grid(True, which='both', linestyle='--')

    # --- Subplot 2: Sigma Parameters ---
    num_sigmas = len(nn_sigma_cols)
    # Generate distinct colors for each sigma line from the coolwarm map
    # Use the blue-ish side for NN and the red-ish side for LM
    nn_sigma_colors = cm.coolwarm(np.linspace(0, 0.4, num_sigmas))
    lm_sigma_colors = cm.coolwarm(np.linspace(0.6, 1.0, num_sigmas))

    # Plot all NN sigmas with varying blue-ish colors
    for i, col in enumerate(nn_sigma_cols):
        axes[1].plot(df['Date'], df[col], color=nn_sigma_colors[i], linestyle='-', label=col)

    # Plot all LM sigmas with varying red-ish colors
    for i, col in enumerate(lm_sigma_cols):
        axes[1].plot(df['Date'], df[col], color=lm_sigma_colors[i], linestyle='--', label=col)

    axes[1].set_title('Evolution of Volatility Parameters (Sigmas)', fontsize=14)
    axes[1].set_ylabel('Parameter Value', fontsize=12)
    axes[1].legend()
    axes[1].grid(True, which='both', linestyle='--')

    # Final adjustments
    axes[1].set_xlabel('Date', fontsize=12)
    fig.autofmt_xdate()
    plt.tight_layout(rect=[0, 0.03, 1, 0.93])
    plt.savefig(save_path)
    plt.close(fig)
    print(f"Saved Plot 3: {save_path}")

# --- PART 2: PER-SWAPTION GRANULAR ANALYSIS ---
def plot_volatility_surface(df: pd.DataFrame, save_path_prefix: str):
    """
    Plot 4: Volatility Surface Reconstruction on Hold-Out Set

    Plots the volatility surfaces reconstructed by the Neural Network and Levenberg-Marquardt models on the hold-out set.

    Parameters
    ----------
    df : pd.DataFrame
        The DataFrame containing the daily comparison results.
    save_path_prefix : str
        The path prefix where the plot will be saved.

    Returns
    -------
    None
    """
    if df.empty: return
    # Choose the last day in the dataset for visualization
    eval_date = pd.to_datetime(df['EvaluationDate']).max()
    date_str = eval_date.strftime('%Y-%m-%d')
    day_df = df[df['EvaluationDate'] == date_str].copy()
    
    if day_df.empty:
        print(f"Could not generate Plot 4: No data found for the latest date {date_str}.")
        return

    day_df['Expiry'] = day_df['ExpiryStr'].apply(parse_tenor_to_years)
    day_df['Tenor'] = day_df['TenorStr'].apply(parse_tenor_to_years)
    day_df.dropna(subset=['Expiry', 'Tenor'], inplace=True)

    fig = plt.figure(figsize=(24, 8))
    fig.suptitle(f'Volatility Surface Reconstruction on Hold-Out Set ({date_str})', fontsize=16)

    # Subplot 1: Market Surface
    ax1 = fig.add_subplot(1, 3, 1, projection='3d')
    ax1.set_title('Market Volatility (Ground Truth)')
    surf1 = ax1.plot_trisurf(day_df['Expiry'], day_df['Tenor'], day_df['MarketVol_bps'], cmap=cm.viridis, antialiased=True)
    
    # Subplot 2: NN Reconstructed Surface
    ax2 = fig.add_subplot(1, 3, 2, projection='3d')
    ax2.set_title('Neural Network Surface')
    surf2 = ax2.plot_trisurf(day_df['Expiry'], day_df['Tenor'], day_df['NN_ModelVol_bps'], cmap=cm.viridis, antialiased=True)

    # Subplot 3: LM Reconstructed Surface
    ax3 = fig.add_subplot(1, 3, 3, projection='3d')
    ax3.set_title('Levenberg-Marquardt Surface')
    surf3 = ax3.plot_trisurf(day_df['Expiry'], day_df['Tenor'], day_df['LM_ModelVol_bps'], cmap=cm.viridis, antialiased=True)

    for ax in [ax1, ax2, ax3]:
        ax.set_xlabel('Expiry (Years)')
        ax.set_ylabel('Tenor (Years)')
        ax.set_zlabel('Volatility (bps)')
        ax.view_init(elev=30, azim=-120)
    
    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    save_path = f"{save_path_prefix}_{date_str}.png"
    plt.savefig(save_path)
    plt.close(fig)
    print(f"Saved Plot 4: {save_path}")

def plot_error_heatmaps(df: pd.DataFrame, save_path: str):
    """
    Plot 5: Mean Prediction Errors (Model - Market) in bps across Volatility Surface

    Plots the mean prediction errors of the Neural Network and Levenberg-Marquardt models
    across the volatility surface. The errors are calculated as the difference between
    the model's predictions and the market's volatility in bps.

    Parameters
    ----------
    df : pd.DataFrame
        The DataFrame containing the comparison results.
    save_path : str
        The path where the plot will be saved.

    Returns
    -------
    None
    """
    df_copy = df.copy()
    df_copy['Expiry'] = df_copy['ExpiryStr'].apply(parse_tenor_to_years)
    df_copy['Tenor'] = df_copy['TenorStr'].apply(parse_tenor_to_years)
    df_copy.dropna(subset=['Expiry', 'Tenor'], inplace=True)

    # Create bins for heatmap
    expiry_bins = pd.cut(df_copy['Expiry'], bins=np.arange(0, 31, 5), right=False)
    tenor_bins = pd.cut(df_copy['Tenor'], bins=np.arange(0, 31, 5), right=False)
    
    nn_pivot = df_copy.pivot_table(index=expiry_bins, columns=tenor_bins, values='NN_Error_bps', aggfunc='mean')
    lm_pivot = df_copy.pivot_table(index=expiry_bins, columns=tenor_bins, values='LM_Error_bps', aggfunc='mean')
    diff_pivot = lm_pivot - nn_pivot # Where LM error is larger than NN error

    # Find a common, symmetric color range for the error plots
    vmax = max(abs(nn_pivot.min().min()), abs(nn_pivot.max().max()), abs(lm_pivot.min().min()), abs(lm_pivot.max().max()))
    
    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24, 7))
    fig.suptitle('Mean Prediction Errors (Model - Market) in bps across Volatility Surface', fontsize=16)

    sns.heatmap(nn_pivot, ax=ax1, cmap='coolwarm', annot=True, fmt=".2f", vmin=-vmax, vmax=vmax)
    ax1.set_title('Neural Network Mean Error')
    ax1.set_xlabel('Tenor Bins')
    ax1.set_ylabel('Expiry Bins')
    
    sns.heatmap(lm_pivot, ax=ax2, cmap='coolwarm', annot=True, fmt=".2f", vmin=-vmax, vmax=vmax)
    ax2.set_title('Levenberg-Marquardt Mean Error')
    ax2.set_xlabel('Tenor Bins')
    ax2.set_ylabel('')

    sns.heatmap(diff_pivot, ax=ax3, cmap='coolwarm', annot=True, fmt=".2f")
    ax3.set_title('Error Difference (LM - NN)')
    ax3.set_xlabel('Tenor Bins')
    ax3.set_ylabel('')

    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    plt.savefig(save_path)
    plt.close(fig)
    print(f"Saved Plot 5: {save_path}")

def plot_error_by_expiry(df: pd.DataFrame, save_path: str):
    """
    Plot 6: Error Distribution by Swaption Expiry Bucket

    Plots the distribution of prediction errors (in bps) for the Neural Network and Levenberg-Marquardt models
    across different expiry buckets.

    Parameters
    ----------
    df : pd.DataFrame
        The DataFrame containing the comparison results.
    save_path : str
        The path where the plot will be saved.

    Returns
    -------
    None
    """
    df_copy = df.copy()
    df_copy['Expiry'] = df_copy['ExpiryStr'].apply(parse_tenor_to_years)
    df_copy.dropna(subset=['Expiry'], inplace=True)
    
    bins = [0, 3, 7, 31]
    labels = ['Short (0-3Y)', 'Medium (3-7Y)', 'Long (7Y+)']
    df_copy['Expiry Bin'] = pd.cut(df_copy['Expiry'], bins=bins, labels=labels, right=False)

    df_melted = df_copy.melt(
        id_vars=['Expiry Bin'],
        value_vars=['NN_Error_bps', 'LM_Error_bps'],
        var_name='Model',
        value_name='Error (bps)'
    )
    df_melted['Model'] = df_melted['Model'].map({
        'NN_Error_bps': 'Neural Network',
        'LM_Error_bps': 'Levenberg-Marquardt'
    })

    fig, ax = plt.subplots(figsize=(12, 7))
    sns.boxplot(data=df_melted, x='Expiry Bin', y='Error (bps)', hue='Model', palette=MODEL_PALETTE, ax=ax)
    ax.axhline(0, color='black', linestyle='--')
    ax.set_title('Error Distribution by Swaption Expiry Bucket', fontsize=16)
    ax.set_xlabel('Expiry Bucket', fontsize=12)
    ax.set_ylabel('Error (bps)', fontsize=12)
    plt.tight_layout()
    plt.savefig(save_path)
    plt.close(fig)
    print(f"Saved Plot 6: {save_path}")

def plot_scatter_comparison(df: pd.DataFrame, save_path: str):
    """
    Plot 7: Plot a scatter comparison between the market volatility and the model volatility
    generated by the Neural Network and the Levenberg-Marquardt model on all
    hold-out swaptions.

    Parameters
    ----------
    df : pd.DataFrame
        The DataFrame containing the comparison results.
    save_path : str
        The path where the plot will be saved.

    Returns
    -------
    None
    """
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7), sharey=True, sharex=True)
    fig.suptitle('Model vs. Market Volatility on All Hold-Out Swaptions', fontsize=16)

    max_val = max(df['MarketVol_bps'].max(), df['NN_ModelVol_bps'].max(), df['LM_ModelVol_bps'].max()) * 1.05
    min_val = min(df['MarketVol_bps'].min(), df['NN_ModelVol_bps'].min(), df['LM_ModelVol_bps'].min()) * 0.95
    
    # NN Plot
    ax1.scatter(df['MarketVol_bps'], df['NN_ModelVol_bps'], alpha=0.3, color=NN_COLOR, s=10)
    ax1.plot([min_val, max_val], [min_val, max_val], 'k--', label='y=x (Perfect Fit)')
    ax1.set_title('Neural Network')
    ax1.set_xlabel('Market Volatility (bps)')
    ax1.set_ylabel('Model Volatility (bps)')
    ax1.legend()
    ax1.set_xlim(min_val, max_val)
    ax1.set_ylim(min_val, max_val)

    # LM Plot
    ax2.scatter(df['MarketVol_bps'], df['LM_ModelVol_bps'], alpha=0.3, color=LM_COLOR, s=10)
    ax2.plot([min_val, max_val], [min_val, max_val], 'k--', label='y=x (Perfect Fit)')
    ax2.set_title('Levenberg-Marquardt')
    ax2.set_xlabel('Market Volatility (bps)')
    ax2.legend()

    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    plt.savefig(save_path)
    plt.close(fig)
    print(f"Saved Plot 7: {save_path}")

def plot_error_by_tenor(df: pd.DataFrame, save_path: str):
    """
    Plot 8: Plot the error distribution for each model across different
    swaption tenor buckets.

    Parameters
    ----------
    df : pd.DataFrame
        The DataFrame containing the comparison results.
    save_path : str
        The path where the plot will be saved.

    Returns
    -------
    None
    """
    df_copy = df.copy()
    df_copy['Tenor'] = df_copy['TenorStr'].apply(parse_tenor_to_years)
    df_copy.dropna(subset=['Tenor'], inplace=True)
    
    bins = [0, 3, 7, 31]
    labels = ['Short (0-3Y)', 'Medium (3-7Y)', 'Long (7Y+)']
    df_copy['Tenor Bin'] = pd.cut(df_copy['Tenor'], bins=bins, labels=labels, right=False)

    df_melted = df_copy.melt(
        id_vars=['Tenor Bin'],
        value_vars=['NN_Error_bps', 'LM_Error_bps'],
        var_name='Model',
        value_name='Error (bps)'
    )
    df_melted['Model'] = df_melted['Model'].map({
        'NN_Error_bps': 'Neural Network',
        'LM_Error_bps': 'Levenberg-Marquardt'
    })

    fig, ax = plt.subplots(figsize=(12, 7))
    sns.boxplot(data=df_melted, x='Tenor Bin', y='Error (bps)', hue='Model', palette=MODEL_PALETTE, ax=ax)
    ax.axhline(0, color='black', linestyle='--')
    ax.set_title('Error Distribution by Swaption Tenor Bucket', fontsize=16)
    ax.set_xlabel('Tenor Bucket', fontsize=12)
    ax.set_ylabel('Error (bps)', fontsize=12)
    plt.tight_layout()
    plt.savefig(save_path)
    plt.close(fig)
    print(f"Saved Plot 11: {save_path}")

def plot_error_by_volatility(df: pd.DataFrame, save_path: str):
    """
    Plot 19: Plot the error distribution for each model across different
    market volatility levels.

    Parameters
    ----------
    df : pd.DataFrame
        The DataFrame containing the comparison results.
    save_path : str
        The path where the plot will be saved.

    Returns
    -------
    None
    """
    df_copy = df.copy()
    
    # Bin by volatility quantiles for robust binning
    try:
        labels = [
            'Low Vol (0-25%)', 
            'Mid Vol (25-75%)', 
            'High Vol (75-100%)'
        ]
        df_copy['Volatility Bin'] = pd.qcut(df_copy['MarketVol_bps'], q=[0, 0.25, 0.75, 1.0], labels=labels)
    except ValueError:
        print("Could not generate Plot 12: Not enough unique volatility points for quantile binning.")
        return

    df_melted = df_copy.melt(
        id_vars=['Volatility Bin'],
        value_vars=['NN_Error_bps', 'LM_Error_bps'],
        var_name='Model',
        value_name='Error (bps)'
    )
    df_melted['Model'] = df_melted['Model'].map({
        'NN_Error_bps': 'Neural Network',
        'LM_Error_bps': 'Levenberg-Marquardt'
    })

    fig, ax = plt.subplots(figsize=(12, 7))
    sns.boxplot(data=df_melted, x='Volatility Bin', y='Error (bps)', hue='Model', palette=MODEL_PALETTE, ax=ax)
    ax.axhline(0, color='black', linestyle='--')
    ax.set_title('Error Distribution by Market Volatility Level', fontsize=16)
    ax.set_xlabel('Market Volatility Quantile', fontsize=12)
    ax.set_ylabel('Error (bps)', fontsize=12)
    plt.tight_layout()
    plt.savefig(save_path)
    plt.close(fig)
    print(f"Saved Plot 12: {save_path}")


# --- MAIN EXECUTION ---
if __name__ == '__main__':
    try:
        print(f"--- Loading data from {COMPARISON_DIR} ---")
        summary_df = pd.read_csv(SUMMARY_CSV, parse_dates=['Date'])
        swaption_df = pd.read_csv(SWAPTION_CSV)
        print("Data loaded successfully.")

        # --- Generate Part 1 Visuals ---
        generate_summary_tables(summary_df, COMPARISON_DIR)
        plot_daily_rmse(summary_df, os.path.join(COMPARISON_DIR, 'plot1_daily_rmse.png'))
        plot_rmse_distribution(summary_df, os.path.join(COMPARISON_DIR, 'plot2_rmse_distribution.png'))
        plot_parameter_evolution(summary_df, os.path.join(COMPARISON_DIR, 'plot3_parameter_evolution.png'))

        # --- Generate Black Volatility RMSE Plot ---
        try:
            summary_df_black = pd.read_csv(SUMMARY_CSV_BLACK, parse_dates=['Date'])
            plot_daily_rmse_black(summary_df_black, os.path.join(COMPARISON_DIR, 'plot4_daily_rmse_black_vol.png'))
        except FileNotFoundError:
            print(f"\nINFO: Black volatility summary file not found at '{SUMMARY_CSV_BLACK}'. Skipping corresponding plot.")

        # --- Generate Part 2 Visuals ---
        plot_volatility_surface(swaption_df, os.path.join(COMPARISON_DIR, 'plot5_volatility_surface'))
        plot_error_heatmaps(swaption_df, os.path.join(COMPARISON_DIR, 'plot6_error_heatmaps.png'))
        plot_error_by_expiry(swaption_df, os.path.join(COMPARISON_DIR, 'plot7_error_by_expiry.png'))
        plot_error_by_tenor(swaption_df, os.path.join(COMPARISON_DIR, 'plot8_error_by_tenor.png'))
        plot_error_by_volatility(swaption_df, os.path.join(COMPARISON_DIR, 'plot9_error_by_volatility.png'))
        plot_scatter_comparison(swaption_df, os.path.join(COMPARISON_DIR, 'plot10_scatter_comparison.png'))
                
        print("\n--- All visualizations have been generated successfully. ---")

    except FileNotFoundError:
        print(f"\nERROR: Could not find result files.")
        print(f"Please ensure '{SUMMARY_CSV}' and '{SWAPTION_CSV}' exist.")
        print("You may need to run 'run_comparison.py' first.")
    except Exception as e:
        print(f"\nAn unexpected error occurred: {e}")
        import traceback
        traceback.print_exc()